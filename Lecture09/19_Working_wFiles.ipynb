{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e68d4f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Author:<br>Felix Gonzalez, P.E. <br> Adjunct Instructor, <br> Division of Professional Studies <br> Computer Science and Electrical Engineering <br> University of Maryland Baltimore County <br> fgonzale@umbc.edu\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967c98d",
   "metadata": {},
   "source": [
    "This notebook provides an overview of basic concepts in workign with various types of data sources and files in the Python Programming Language and Jupyter Notebooks. These data sources include files such as txt, json, and csv. The notebook also includes a discussion of various functions and libraries as well as methods on working with multiple data sources files. As a data scientist you will have to work with data in multiple files as well as multiple data file types. In many cases you will need to consolidate, merge, or concatenate to make the dataset more useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a857c8f7",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "[Python Libraries in this Notebook](#Python-Libraries-in-this-Notebook)\n",
    "\n",
    "[OS Library](#OS-Library)\n",
    "\n",
    "- [Working Directory Path Environment](#Working-Directory-Path-Environment)\n",
    "\n",
    "- [Working in the Directory](#Working-in-the-Directory)\n",
    "\n",
    "[Pandas: Working with Multiple Files](#Pandas:-Working-with-Multiple-Files)\n",
    "\n",
    "- [Reading Multiple CSV Files and Pandas: Electricity Use Data Example](#Reading-Multiple-CSV-Files-and-Pandas:-Electricity-Use-Data-Example)\n",
    "\n",
    "[Reading Data Line By Line](#Reading-Data-Line-By-Line)\n",
    "\n",
    "[Working with PDFs](#Working-with-PDFs)\n",
    "\n",
    "[Python Built-In Functions for Loading Data (OPTIONAL)](#Python-Built-In-Functions-for-Loading-Data-(OPTIONAL))\n",
    "\n",
    "- [Open Function](#Open-Function)\n",
    "\n",
    "- [With Statement](#With-Statement)\n",
    "\n",
    "- [Example with Numerical Data in a TXT File](#Example-with-Numerical-Data-in-a-TXT-File)\n",
    "\n",
    "[JSON Library: JSON Files (OPTIONAL)](#JSON-Library:-JSON-Files-(OPTIONAL))\n",
    "\n",
    "[Working with CSV Files (CSV Library)](#Working-with-CSV-Files-(CSV-Library))\n",
    "\n",
    "[Reading Multiple TXT Files (OPTIONAL)](#Reading-Multiple-TXT-Files-(OPTIONAL))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240b1ad",
   "metadata": {},
   "source": [
    "# Python Libraries in this Notebook\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e28cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "import csv\n",
    "import re\n",
    "import fileinput\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ee730",
   "metadata": {},
   "source": [
    "# OS Library\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The Operating System (OS) module provides a portable way of using OS dependent functionality. There are various useful functions and modules within the OS library. Some of these include:\n",
    "- Open() function: read or write a file  \n",
    "- Os.path module: Read and manipulate paths  \n",
    "- Fileinput module: Read all the lines in all the files on the command line\n",
    "- Tempfile module: Creating temporary files and directories \n",
    "- shutil module: High-level file and directory handling\n",
    "\n",
    "There are other libraries that also make it easy to work with files such as the Glob library.\n",
    "\n",
    "Documentation References:\n",
    "- OS Library: https://docs.python.org/3/library/os.html\n",
    "- Glob Library: https://docs.python.org/3/library/glob.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104a01a",
   "metadata": {},
   "source": [
    "There are a few things to remember and that will vary from system to system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956d5e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.linesep # Note on line separator which will vary depending in the OS system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f93dc3b",
   "metadata": {},
   "source": [
    "From the OS Library documentation:\n",
    "\n",
    "os.linesep: \"The string used to separate (or, rather, terminate) lines on the current platform. This may be a single character, such as '\\n' for POSIX, or multiple characters, for example, '\\r\\n' for Windows. Do not use os.linesep as a line terminator when writing files opened in text mode (the default); use a single '\\n' instead, on all platforms.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65651b5",
   "metadata": {},
   "source": [
    "Also recall that paths in windows uses the \"\\\" and in Unix/MacOS is \"/\" and depending on your operating system you may get different resutls in the cell above. The Unix style path works on both operating systems whithin the Python environment and should be the __preferred__.  Recall that the \\ is also an escape character and __NOT__ the preferred approach.\n",
    "\n",
    "References:\n",
    "- https://stackoverflow.com/questions/1589930/so-what-is-the-right-direction-of-the-paths-slash-or-under-windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1701171b",
   "metadata": {},
   "source": [
    "#### Working Directory Path Environment\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb98132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3;C:\\ProgramData\\anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\anaconda3\\Library\\usr\\bin;C:\\ProgramData\\anaconda3\\Library\\bin;C:\\ProgramData\\anaconda3\\Scripts;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Users\\felix\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\felix\\AppData\\Roaming\\Python\\Python312\\Scripts;\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d876c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'HOME'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If in Windows, the home environment/folder will not work. See next cell.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHOME\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m<frozen os>:714\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'HOME'"
     ]
    }
   ],
   "source": [
    "# If in Windows, the home environment/folder will not work. See next cell.\n",
    "print(os.environ[\"HOME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3476025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\felix\n"
     ]
    }
   ],
   "source": [
    "#If in Windows need to use the follwoing instead of os.environ[\"HOME\"]\n",
    "home_folder = os.path.expanduser('~')\n",
    "print(home_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31c2c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Felix_ASUS_Docs\\\\1A_Python_Projects\\\\DATA601_Files\\\\Lecture09'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current working directory.\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cd92d6",
   "metadata": {},
   "source": [
    "#### Working in the Directory\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a988b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '19_Working_wFiles.ipynb',\n",
       " '20_Working_with_WebData_and_APIs.ipynb',\n",
       " '21a_SQL_DB_Test_File_Creation.ipynb',\n",
       " '21b_Relational_Databases_and_SQL.ipynb',\n",
       " 'database.sqlite',\n",
       " 'input_data',\n",
       " 'output_data']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of everything in the present directory (Note: Does not include files in subfolders)\n",
    "os.listdir(path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44fe4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the command mkdir (make a directory) in the system shell\n",
    "os.system('mkdir test_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca802709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '19_Working_wFiles.ipynb',\n",
       " '20_Working_with_WebData_and_APIs.ipynb',\n",
       " '21a_SQL_DB_Test_File_Creation.ipynb',\n",
       " '21b_Relational_Databases_and_SQL.ipynb',\n",
       " 'database.sqlite',\n",
       " 'input_data',\n",
       " 'output_data',\n",
       " 'test_folder']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list everything in the present directory\n",
    "os.listdir(path='.') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4533b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have a new folder called \"test_folder\". let's go into that directory\n",
    "os.chdir('./test_folder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b73c4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Felix_ASUS_Docs\\\\1A_Python_Projects\\\\DATA601_Files\\\\Lecture09\\\\test_folder'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5e5df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Felix_ASUS_Docs\\\\1A_Python_Projects\\\\DATA601_Files\\\\Lecture09'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's go back to previous folder\n",
    "os.chdir('./..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e46109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mkdir test_folder2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95a77744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a folder inside the test_folder2\n",
    "#os.system('mkdir test_folder2/test_subfolder1')\n",
    "\n",
    "# Alternatively to os.system, we can use the os.mkdir.\n",
    "os.mkdir('test_folder2/test_subfolder1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28dee1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "input_data\n",
      "output_data\n",
      "test_folder\n",
      "test_folder2\n"
     ]
    }
   ],
   "source": [
    "# let's list subdirectories using the pathlib library\n",
    "p = pathlib.Path('.') # current directory\n",
    "for x in p.iterdir():\n",
    "    if x.is_dir():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fa01b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A FILE AT CURRENT DIRECTORY\n",
    "f = open('test_file.txt',\"w+\")\n",
    "\n",
    "# WRITING IN A FILE\n",
    "for x in range(10):\n",
    "    f.write(\"This is line %d\\r\\n\" % (x+1))\n",
    "    \n",
    "# CLOSING A FILE\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "520595b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPENING AN EXISTING FILE AND APPENDING IT\n",
    "g = open(\"test_file.txt\",\"+a\")\n",
    "\n",
    "for x in range(5):\n",
    "    g.write(\"Appended line %d\\r\\n\" % (x+1))\n",
    "\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f94fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is line 1\n",
      "\n",
      "This is line 2\n",
      "\n",
      "This is line 3\n",
      "\n",
      "This is line 4\n",
      "\n",
      "This is line 5\n",
      "\n",
      "This is line 6\n",
      "\n",
      "This is line 7\n",
      "\n",
      "This is line 8\n",
      "\n",
      "This is line 9\n",
      "\n",
      "This is line 10\n",
      "\n",
      "Appended line 1\n",
      "\n",
      "Appended line 2\n",
      "\n",
      "Appended line 3\n",
      "\n",
      "Appended line 4\n",
      "\n",
      "Appended line 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# READING A LOCAL FILE LINE BY LINE (More on this in later sections).\n",
    "# See section \"Reading Data Line By Line\"\n",
    "with open('test_file.txt','r') as h:\n",
    "    for line in h:\n",
    "        print(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04c7fb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "input_data\n",
      "output_data\n",
      "test_folder\n",
      "test_folder2\n"
     ]
    }
   ],
   "source": [
    "# let's list subdirectories (if any) using the pathlib library\n",
    "p = pathlib.Path('.') # current directory\n",
    "for x in p.iterdir():\n",
    "    if x.is_dir():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c767cdf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 145] The directory is not empty: 'test_folder2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Let's remove the two directories that we created.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mrmdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_folder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m os\u001b[38;5;241m.\u001b[39mrmdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_folder2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 145] The directory is not empty: 'test_folder2'"
     ]
    }
   ],
   "source": [
    "# Let's remove the two directories that we created.\n",
    "os.rmdir('test_folder')\n",
    "os.rmdir('test_folder2') # Will give an error because the folder is not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "032b9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove directory and subdirectories use the shutil library\n",
    "shutil.rmtree('test_folder2')\n",
    "#shutil.rmtree('../test_folder2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bac7e1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "input_data\n",
      "output_data\n"
     ]
    }
   ],
   "source": [
    "# Let's list subdirectories (if any) using the pathlib library\n",
    "p = pathlib.Path('.') # current directory\n",
    "for x in p.iterdir():\n",
    "    if x.is_dir():\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2956b",
   "metadata": {},
   "source": [
    "Using the glob library let's list all the txt files in this folder and subfolders using the glob library. The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order. \n",
    "\n",
    "Documentation References:\n",
    "- https://docs.python.org/3/library/glob.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba13f580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_file.txt',\n",
       " 'input_data\\\\anotherfile.txt',\n",
       " 'input_data\\\\bread.txt',\n",
       " 'input_data\\\\ex1data1.txt',\n",
       " 'input_data\\\\text_files\\\\example3.txt',\n",
       " 'input_data\\\\text_files\\\\FAME.TXT',\n",
       " 'input_data\\\\text_files\\\\Genescan.txt',\n",
       " 'output_data\\\\anotherfile.txt',\n",
       " 'output_data\\\\json_data.txt',\n",
       " 'output_data\\\\textout.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('**/*.txt', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb9b12",
   "metadata": {},
   "source": [
    "Another option to obtain all the files in the directory is to use the os.walk() function.\n",
    "\n",
    "Documentation References:\n",
    "- os.walk(): https://docs.python.org/3/library/os.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9730caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_tuple = [x for x in os.walk(top = './')] # Produces a 3-tuple of (dirpath, dirnames, filenames)\n",
    "\n",
    "all_files_dir = [] # Defines a starting empty list for the all_files_dir.\n",
    "\n",
    "for i in range(len(all_files_tuple)): # Iterates thru each index or element in all_files_tuple.\n",
    "    # Iterates thru files in dir and only select files in directory with specified extension (case insensitive).\n",
    "    txt_files = [filename for filename in os.listdir(all_files_tuple[i][0]) if filename.lower().endswith('.txt'.lower())]\n",
    "    # Combines both the relative path and filename\n",
    "    txt_files = [all_files_tuple[i][0] +'/'+ filename  for filename in txt_files]\n",
    "    # Consolidates all files from the path being iterated into the main list.\n",
    "    all_files_dir = all_files_dir + txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cf2b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./',\n",
       "  ['.ipynb_checkpoints', 'input_data', 'output_data'],\n",
       "  ['19_Working_wFiles.ipynb',\n",
       "   '20_Working_with_WebData_and_APIs.ipynb',\n",
       "   '21a_SQL_DB_Test_File_Creation.ipynb',\n",
       "   '21b_Relational_Databases_and_SQL.ipynb',\n",
       "   'database.sqlite',\n",
       "   'test_file.txt']),\n",
       " ('./.ipynb_checkpoints',\n",
       "  [],\n",
       "  ['19_Working_wFiles-checkpoint.ipynb',\n",
       "   '20_Working_with_WebData_and_APIs-checkpoint.ipynb',\n",
       "   '21b_Relational_Databases_and_SQL-checkpoint.ipynb']),\n",
       " ('./input_data',\n",
       "  ['airline_data', 'electricity_use_data_cleaned', 'text_files'],\n",
       "  ['addresses.csv',\n",
       "   'anotherfile.txt',\n",
       "   'bread.txt',\n",
       "   'csv_plain_file.csv',\n",
       "   'ex1data1.txt',\n",
       "   'geo_data.json',\n",
       "   'NRC_ASP_DATA_from_Public_ASP_Dashboard.csv']),\n",
       " ('./input_data\\\\airline_data',\n",
       "  [],\n",
       "  ['airlines.csv',\n",
       "   'airports.csv',\n",
       "   'flights.csv',\n",
       "   'ZIPCODE_SQFEET_HEATERTYPE_HOUSETYPE_HOUSEUSAGE-TEMPLATE.csv']),\n",
       " ('./input_data\\\\electricity_use_data_cleaned',\n",
       "  [],\n",
       "  ['20737_1006_electric_singlefamily_primary_cleaned.csv',\n",
       "   '20871_2400_GAS_TOWNHOUSE_PRIMARY_cleaned.csv',\n",
       "   '20871_3200_electric_singlefamily_primary_cleaned.csv',\n",
       "   '20874_NA_ELECTRIC_Apartiment_PRIMARY_cleaned.csv',\n",
       "   '20904_1700_ELECTRIC_TOWNHOUSE_PRIMARY_cleaned.csv']),\n",
       " ('./input_data\\\\text_files',\n",
       "  [],\n",
       "  ['example3.txt', 'FAME.TXT', 'Genescan.txt']),\n",
       " ('./output_data',\n",
       "  ['airline_data', 'API_initial_download'],\n",
       "  ['anotherfile.txt', 'dataout1.csv', 'json_data.txt', 'textout.txt']),\n",
       " ('./output_data\\\\airline_data',\n",
       "  [],\n",
       "  ['df_flights_cleaned_2.csv', 'flights_database.db']),\n",
       " ('./output_data\\\\API_initial_download',\n",
       "  [],\n",
       "  ['fed_register_data_accident.json',\n",
       "   'fed_register_data_drug.json',\n",
       "   'fed_register_data_food.json',\n",
       "   'fed_register_data_text.json',\n",
       "   'fed_register_data_weather.json'])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e87ea50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.//test_file.txt',\n",
       " './input_data/anotherfile.txt',\n",
       " './input_data/bread.txt',\n",
       " './input_data/ex1data1.txt',\n",
       " './input_data\\\\text_files/example3.txt',\n",
       " './input_data\\\\text_files/FAME.TXT',\n",
       " './input_data\\\\text_files/Genescan.txt',\n",
       " './output_data/anotherfile.txt',\n",
       " './output_data/json_data.txt',\n",
       " './output_data/textout.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_dir # The output here is similar to the output in the glob.glob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0e436e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find files that are in subfolders only.\n",
    "sub_folders = [] # Defines a starting empty List of subfolder names that will have specified file type (e.g., csv).\n",
    "\n",
    "# Iterates thru all file directories to extract Folder name. Located at all_files_dir[i].split('/')[2]\n",
    "for i in range(len(all_files_dir)):\n",
    "    sub_folders = sub_folders + [all_files_dir[i].split('/')[2]]\n",
    "sub_folders = list(set(sub_folders)) # Creates unique list of files in subfolders by removing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21bb57f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex1data1.txt',\n",
       " 'FAME.TXT',\n",
       " 'test_file.txt',\n",
       " 'example3.txt',\n",
       " 'bread.txt',\n",
       " 'Genescan.txt',\n",
       " 'json_data.txt',\n",
       " 'textout.txt',\n",
       " 'anotherfile.txt']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_folders # List of files in subfolders (No duplicates) Can remove the set if there would be duplicate names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3de96e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_data\\\\anotherfile.txt',\n",
       " 'input_data\\\\bread.txt',\n",
       " 'input_data\\\\ex1data1.txt',\n",
       " 'input_data\\\\text_files\\\\example3.txt',\n",
       " 'input_data\\\\text_files\\\\FAME.TXT',\n",
       " 'input_data\\\\text_files\\\\Genescan.txt',\n",
       " 'output_data\\\\anotherfile.txt',\n",
       " 'output_data\\\\json_data.txt',\n",
       " 'output_data\\\\textout.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's remove the test_file.txt that we created earlier and check the txt files in the directory.\n",
    "os.remove('./test_file.txt')\n",
    "glob.glob('**/*.txt', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c511269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_data\\\\addresses.csv',\n",
       " 'input_data\\\\csv_plain_file.csv',\n",
       " 'input_data\\\\NRC_ASP_DATA_from_Public_ASP_Dashboard.csv']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('input_data/*.csv', recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40d870",
   "metadata": {},
   "source": [
    "# Pandas: Working with Multiple Files\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Up to this moment we have used Pandas to load data from a single file and in a few cases join/merge/concatenate with data from another file. As a data scientist you will have to work with data in multiple files and in many cases you will need to consolidate, merge, or concatenate to make the dataset more useful. This section discusses some examples on working with multiple files using OS and Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc3839b",
   "metadata": {},
   "source": [
    "#### Reading Multiple CSV Files and Pandas: Electricity Use Data Example\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "When reading and extracting data from multiple files there may be various ways. In this case we will explore extracting data from the electricity use data that we collected at the beginning of the class and explore various challenges that we may encounter when processing the data files. More often than not, when the data was collected manually by various people there may be differences in the files that may provide challenges on how the data is extracted.\n",
    "\n",
    "The first step is to manually get familiarized with the datasets as well as the columns and features collected. Once the feature names are explored and normalized (i.e., made the same) we can continue to merge the datasets and extract any data that we may need to extract from the filename or the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49bc1d4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('./input_data/electricity_use_data_cleaned/',\n",
       "  [],\n",
       "  ['20737_1006_electric_singlefamily_primary_cleaned.csv',\n",
       "   '20871_2400_GAS_TOWNHOUSE_PRIMARY_cleaned.csv',\n",
       "   '20871_3200_electric_singlefamily_primary_cleaned.csv',\n",
       "   '20874_NA_ELECTRIC_Apartiment_PRIMARY_cleaned.csv',\n",
       "   '20904_1700_ELECTRIC_TOWNHOUSE_PRIMARY_cleaned.csv'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See Documentation for os.walk(): https://docs.python.org/3/library/os.html\n",
    "# Produces a 3-tuple of (dirpath, dirnames, filenames)\n",
    "all_files_tuple = [x for x in os.walk(top = './input_data/electricity_use_data_cleaned/')] # Produces a 3-tuple of (dirpath, dirnames, filenames)\n",
    "all_files_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdbb5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20737_1006_electric_singlefamily_primary_cleaned.csv',\n",
       " '20871_2400_GAS_TOWNHOUSE_PRIMARY_cleaned.csv',\n",
       " '20871_3200_electric_singlefamily_primary_cleaned.csv',\n",
       " '20874_NA_ELECTRIC_Apartiment_PRIMARY_cleaned.csv',\n",
       " '20904_1700_ELECTRIC_TOWNHOUSE_PRIMARY_cleaned.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the list of the file names.\n",
    "all_files_tuple[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a14a289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List has no duplicate files: True.\n",
      "There are 5 specified file type (e.g., csv).\n",
      "Unique subfolders with specified file type (e.g., csv): {'electricity_use_data_cleaned'}.\n",
      "Sample of three files: ['./input_data/electricity_use_data_cleaned//20737_1006_electric_singlefamily_primary_cleaned.csv', './input_data/electricity_use_data_cleaned//20871_2400_GAS_TOWNHOUSE_PRIMARY_cleaned.csv', './input_data/electricity_use_data_cleaned//20871_3200_electric_singlefamily_primary_cleaned.csv'].\n"
     ]
    }
   ],
   "source": [
    "# Goal: I want to obtain a list of the specified type file (e.g., csv) with their relative directory to later iterate thru.\n",
    "all_files_dir = [] # Defines a starting empty list for the all_files_dir.\n",
    "sub_folders = [] # Defines a starting empty List of subfolder names that will have specified file type (e.g., csv).\n",
    "\n",
    "for i in range(len(all_files_tuple)): # Iterates thru each index or element in all_files_tuple.\n",
    "    # Iterates thru files in dir and only select files in directory with specified extension (case insensitive).\n",
    "    csv_files = [filename for filename in os.listdir(all_files_tuple[i][0]) if filename.lower().endswith('.csv'.lower())]\n",
    "    # Combines both the relative path and filename\n",
    "    csv_files = [all_files_tuple[i][0] +'/'+ filename  for filename in csv_files]\n",
    "    # Consolidates all files from the path being iterated into the main list.\n",
    "    all_files_dir = all_files_dir + csv_files\n",
    "    \n",
    "# Iterates thru all file directories to extract Folder name. Located at all_files_dir[i].split('/')[2]\n",
    "#for i in range(len(all_files_dir)):\n",
    "    sub_folders = sub_folders + [all_files_dir[i].split('/')[2]]   \n",
    "sub_folders = set(sub_folders) # Creates unique list of subfolders by removing duplicates.\n",
    "# The subfolders could mean a year a location a zipcode or some other important information.\n",
    "# Because there are no subfolders in the input_data/electricity_use_data_cleaned this will be an empty list.\n",
    "\n",
    "# Checks if final list has not duplicate files.\n",
    "print(f'List has no duplicate files: {len(all_files_dir) == len(set(all_files_dir))}.')\n",
    "print(f'There are {len(all_files_dir)} specified file type (e.g., csv).') # Shows how many files are in the final list.\n",
    "print(f'Unique subfolders with specified file type (e.g., csv): {sub_folders}.') # Show list of sub-folders.\n",
    "print(f'Sample of three files: {all_files_dir[:3]}.') # Shows only the first 3 files in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45cd45d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./input_data/electricity_use_data_cleaned//20737_1006_electric_singlefamily_primary_cleaned.csv',\n",
       " './input_data/electricity_use_data_cleaned//20871_2400_GAS_TOWNHOUSE_PRIMARY_cleaned.csv',\n",
       " './input_data/electricity_use_data_cleaned//20871_3200_electric_singlefamily_primary_cleaned.csv',\n",
       " './input_data/electricity_use_data_cleaned//20874_NA_ELECTRIC_Apartiment_PRIMARY_cleaned.csv',\n",
       " './input_data/electricity_use_data_cleaned//20904_1700_ELECTRIC_TOWNHOUSE_PRIMARY_cleaned.csv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files_dir # In this case there are only a handful of files so we can see the full list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaab2cc",
   "metadata": {},
   "source": [
    "After we know the file paths for the data that we want, we have various options:\n",
    "1. We can initialize the main dataframe by creating a new blank dataframe with the required columns \n",
    "2. Use the columns from the TEMPLATE but we also need to add the columns related to the file names.\n",
    "\n",
    "However, before attempting this we should manually open a few of the CSV files to see if we can spot potential challenges or problems. The original files submitted by students can be found under 'Homework/Special_HW_Home_Electricity_Consumption' folder. The files in the input_data/electricity_use_data_cleaned has been manually fixed. Issues that we can observe in the data:\n",
    "- Different date formats\n",
    "- Some dataframes used a date range while others estimated the month and year. \n",
    "- Some others added extra data that seemed to be available.\n",
    "- Issues with column naming.\n",
    "\n",
    "Note that the instructions were vague on purpose to demonstrate potential issues that may arise during the data collection stage. Even when instructions are clear you will encounter challenges like this. Coordinating during data collection can make improvements in the quality of the data and improve the insights when it is analyzed. Issues in the data collection can sometimes cause that the data is unusable and having to be discarded. \n",
    "\n",
    "There are a few things that we can do to solve the issue.\n",
    "1. If we only had a handful of files we can manually make the change (which is the case here). In some cases we may have to do some assumptions to make the data usable.\n",
    "2. If we had lots of files (e.g., hundreds) we may need to create an if statement that detects the type of file issue, then do either of:\n",
    "    a. fix the issue before extracting\n",
    "    b. extract the data from the appropriate location\n",
    "\n",
    "Another issue that we could probably see is that given the current structure of the dataset, there will be a high likelihood that we may have duplicates in the data. For example, if we obtain more data, there is a high likelihood that our neighbors data may be very similar and in case of the filenaming exactly the same. This will cause issues as the operating systems do not allow files to have the same filename. The address could have been a good addition to the filename to avoid this. \n",
    "\n",
    "Depending on the issue addressing them may be easy, to very difficult to impossible. Option 2 above assumes that the issues is consistent within various files and that the majority of the data collected was using the correct template or format and hence the issue can use an if statement to be identified.. Imagine having this issues accross hundreds of files that we need to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd9146e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input_data/electricity_use_data_cleaned//20904_1700_ELECTRIC_TOWNHOUSE_PRIMARY_cleaned.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date</td>\n",
       "      <td>Bill Amount</td>\n",
       "      <td>Days in Billing Cycle</td>\n",
       "      <td>KWH Usage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023 February</td>\n",
       "      <td>280</td>\n",
       "      <td>30</td>\n",
       "      <td>1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023 January</td>\n",
       "      <td>450</td>\n",
       "      <td>35</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022 December</td>\n",
       "      <td>290</td>\n",
       "      <td>30</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022 November</td>\n",
       "      <td>270</td>\n",
       "      <td>28</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1                      2          3\n",
       "0            Date  Bill Amount  Days in Billing Cycle  KWH Usage\n",
       "1   2023 February          280                     30       1400\n",
       "2    2023 January          450                     35       2500\n",
       "3  2022 December           290                     30       1700\n",
       "4   2022 November          270                     28        900"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the TEMPLATE dataframe, other files and explore their columns.\n",
    "# Note that the columns are in the first row.\n",
    "i = -1 # Use from -1 to zero to postive.\n",
    "print(csv_files[i])\n",
    "pd.read_csv(csv_files[i], header = None).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa411f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Home Square Footage</th>\n",
       "      <th>Heater Type</th>\n",
       "      <th>Home Type</th>\n",
       "      <th>Home Usage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bill Amount</th>\n",
       "      <th>Days in Billing Cycle</th>\n",
       "      <th>KWH Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Zipcode, Home Square Footage, Heater Type, Home Type, Home Usage, Date, Bill Amount, Days in Billing Cycle, KWH Usage]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to combine all the dataframes with electricity use data including the data in the filename\n",
    "# One approache could be to initialize a main empty dataframe where the data gets added with the right columns.\n",
    "# Let's initialize an empty main DataFrame with the required columns.\n",
    "df_electricity_usage = pd.DataFrame(columns = ['Zipcode', 'Home Square Footage', 'Heater Type', 'Home Type', \n",
    "                                               'Home Usage', 'Date', 'Bill Amount', 'Days in Billing Cycle', \n",
    "                                               'KWH Usage'])\n",
    "# Note that some of the data will be in the filename while other data will be inside the file.\n",
    "df_electricity_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2f39df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20737', '1006', 'electric', 'singlefamily', 'primary', 'cleaned.csv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the data for file at index 0.\n",
    "i = 0\n",
    "file_name_list = csv_files[i].split(\"/\")[4].split('_')\n",
    "file_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e49083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Usage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bill Amount</th>\n",
       "      <th>Days in Billing Cycle</th>\n",
       "      <th>KWH Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>primary</td>\n",
       "      <td>2021 December</td>\n",
       "      <td>$117.03</td>\n",
       "      <td>32</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 January</td>\n",
       "      <td>$156.02</td>\n",
       "      <td>27</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 February</td>\n",
       "      <td>$98.69</td>\n",
       "      <td>28</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 March</td>\n",
       "      <td>$78.70</td>\n",
       "      <td>30</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 April</td>\n",
       "      <td>$67.62</td>\n",
       "      <td>30</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 May</td>\n",
       "      <td>$144.69</td>\n",
       "      <td>29</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 June</td>\n",
       "      <td>$226.59</td>\n",
       "      <td>32</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 July</td>\n",
       "      <td>$221.60</td>\n",
       "      <td>27</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 August</td>\n",
       "      <td>$235.64</td>\n",
       "      <td>31</td>\n",
       "      <td>1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 September</td>\n",
       "      <td>$145.08</td>\n",
       "      <td>30</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 October</td>\n",
       "      <td>$93.93</td>\n",
       "      <td>28</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>primary</td>\n",
       "      <td>2022 November</td>\n",
       "      <td>$168.16</td>\n",
       "      <td>29</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Home Usage            Date Bill Amount  Days in Billing Cycle  KWH Usage\n",
       "0     primary   2021 December    $117.03                      32        857\n",
       "1     primary    2022 January    $156.02                      27       1114\n",
       "2     primary   2022 February     $98.69                      28        681\n",
       "3     primary      2022 March     $78.70                      30        532\n",
       "4     primary      2022 April     $67.62                      30        429\n",
       "5     primary        2022 May    $144.69                      29        851\n",
       "6     primary       2022 June    $226.59                      32       1436\n",
       "7     primary       2022 July    $221.60                      27       1445\n",
       "8     primary     2022 August    $235.64                      31       1436\n",
       "9     primary  2022 September    $145.08                      30        884\n",
       "10    primary    2022 October     $93.93                      28        566\n",
       "11    primary   2022 November    $168.16                      29       1057"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf = pd.read_csv(csv_files[i], header = 0)\n",
    "# We can add a column of the filename information with the insert function.\n",
    "testdf.insert(0, \"Home Usage\", file_name_list[4])\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90b517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create a loop that iterates thru all the files.\n",
    "for i in range(len(csv_files)):\n",
    "    # Loading csv file as temporary df.\n",
    "    tempdf = pd.read_csv(csv_files[i], header = 0) # Header located at row index 0.\n",
    "    # Filename information in a list using underscore as delimiter.\n",
    "    file_name_list = csv_files[i].split(\"/\")[4].split('_')\n",
    "    # Inserts the new columsn for Zipcode, Home Square Footage, Heater type, and Home Usage\n",
    "    tempdf.insert(0, \"Home Usage\", file_name_list[4])\n",
    "    tempdf.insert(0, \"Home Type\", file_name_list[3])\n",
    "    tempdf.insert(0, \"Heater Type\", file_name_list[2])\n",
    "    tempdf.insert(0, \"Home Square Footage\", file_name_list[1])\n",
    "    tempdf.insert(0, \"Zipcode\", file_name_list[0])\n",
    "\n",
    "    # Before concatenating, \n",
    "    # Let's check the tempdf has the same number of features as the main dataframe (e.g., df_electricity_usage).\n",
    "    try:\n",
    "        if all(df_electricity_usage.columns == tempdf.columns): # If columns don't match will give an error hnce the try-except.\n",
    "            df_electricity_usage = pd.concat([df_electricity_usage, tempdf], axis=0) # Adds tempdf at bottom of main df.\n",
    "    except:\n",
    "        print(f'PROCESS STOPPED: Following file does not has the same features/columns:')\n",
    "        print(f'{csv_files[i]}') # Prints the file with the issue.\n",
    "        break # If there is a row that does not meet this condition for loop breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98202bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Home Square Footage</th>\n",
       "      <th>Heater Type</th>\n",
       "      <th>Home Type</th>\n",
       "      <th>Home Usage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bill Amount</th>\n",
       "      <th>Days in Billing Cycle</th>\n",
       "      <th>KWH Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2021 December</td>\n",
       "      <td>$117.03</td>\n",
       "      <td>32</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 January</td>\n",
       "      <td>$156.02</td>\n",
       "      <td>27</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 February</td>\n",
       "      <td>$98.69</td>\n",
       "      <td>28</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 March</td>\n",
       "      <td>$78.70</td>\n",
       "      <td>30</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 April</td>\n",
       "      <td>$67.62</td>\n",
       "      <td>30</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 June</td>\n",
       "      <td>140</td>\n",
       "      <td>30</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 May</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 April</td>\n",
       "      <td>160</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 March</td>\n",
       "      <td>265</td>\n",
       "      <td>31</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 February</td>\n",
       "      <td>260</td>\n",
       "      <td>30</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode Home Square Footage Heater Type     Home Type Home Usage  \\\n",
       "0    20737                1006    electric  singlefamily    primary   \n",
       "1    20737                1006    electric  singlefamily    primary   \n",
       "2    20737                1006    electric  singlefamily    primary   \n",
       "3    20737                1006    electric  singlefamily    primary   \n",
       "4    20737                1006    electric  singlefamily    primary   \n",
       "..     ...                 ...         ...           ...        ...   \n",
       "8    20904                1700    ELECTRIC     TOWNHOUSE    PRIMARY   \n",
       "9    20904                1700    ELECTRIC     TOWNHOUSE    PRIMARY   \n",
       "10   20904                1700    ELECTRIC     TOWNHOUSE    PRIMARY   \n",
       "11   20904                1700    ELECTRIC     TOWNHOUSE    PRIMARY   \n",
       "12   20904                1700    ELECTRIC     TOWNHOUSE    PRIMARY   \n",
       "\n",
       "             Date Bill Amount Days in Billing Cycle KWH Usage  \n",
       "0   2021 December    $117.03                     32       857  \n",
       "1    2022 January    $156.02                     27      1114  \n",
       "2   2022 February     $98.69                     28       681  \n",
       "3      2022 March     $78.70                     30       532  \n",
       "4      2022 April     $67.62                     30       429  \n",
       "..            ...         ...                   ...       ...  \n",
       "8       2022 June         140                    30       800  \n",
       "9        2022 May         150                    31       900  \n",
       "10     2022 April         160                    31      1200  \n",
       "11     2022 March         265                    31      2000  \n",
       "12  2022 February         260                    30      2000  \n",
       "\n",
       "[78 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_electricity_usage.shape)\n",
    "df_electricity_usage#.head(60)\n",
    "# Note there are 91 rows but the last row index is 12?\n",
    "# Should have used or should use the reset_index.\n",
    "# If this goes unnoticed you will potentially have issues later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "819fe04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1006'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if I use an index based data selection and filter?\n",
    "df_electricity_usage.iloc[0, 1] # Only seems to select the first index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "717a383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Home Square Footage</th>\n",
       "      <th>Heater Type</th>\n",
       "      <th>Home Type</th>\n",
       "      <th>Home Usage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bill Amount</th>\n",
       "      <th>Days in Billing Cycle</th>\n",
       "      <th>KWH Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2021 December</td>\n",
       "      <td>$117.03</td>\n",
       "      <td>32</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 January</td>\n",
       "      <td>$156.02</td>\n",
       "      <td>27</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20737</td>\n",
       "      <td>1006</td>\n",
       "      <td>electric</td>\n",
       "      <td>singlefamily</td>\n",
       "      <td>primary</td>\n",
       "      <td>2022 February</td>\n",
       "      <td>$98.69</td>\n",
       "      <td>28</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Zipcode Home Square Footage Heater Type     Home Type Home Usage  \\\n",
       "0   20737                1006    electric  singlefamily    primary   \n",
       "1   20737                1006    electric  singlefamily    primary   \n",
       "2   20737                1006    electric  singlefamily    primary   \n",
       "\n",
       "            Date Bill Amount Days in Billing Cycle KWH Usage  \n",
       "0  2021 December    $117.03                     32       857  \n",
       "1   2022 January    $156.02                     27      1114  \n",
       "2  2022 February     $98.69                     28       681  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_electricity_usage.iloc[0:3, :] # Only seems to select the first index range 0 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf114e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Home Square Footage</th>\n",
       "      <th>Heater Type</th>\n",
       "      <th>Home Type</th>\n",
       "      <th>Home Usage</th>\n",
       "      <th>Date</th>\n",
       "      <th>Bill Amount</th>\n",
       "      <th>Days in Billing Cycle</th>\n",
       "      <th>KWH Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 June</td>\n",
       "      <td>140</td>\n",
       "      <td>30</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 May</td>\n",
       "      <td>150</td>\n",
       "      <td>31</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 April</td>\n",
       "      <td>160</td>\n",
       "      <td>31</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 March</td>\n",
       "      <td>265</td>\n",
       "      <td>31</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>20904</td>\n",
       "      <td>1700</td>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>TOWNHOUSE</td>\n",
       "      <td>PRIMARY</td>\n",
       "      <td>2022 February</td>\n",
       "      <td>260</td>\n",
       "      <td>30</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Zipcode Home Square Footage Heater Type  Home Type Home Usage  \\\n",
       "73   20904                1700    ELECTRIC  TOWNHOUSE    PRIMARY   \n",
       "74   20904                1700    ELECTRIC  TOWNHOUSE    PRIMARY   \n",
       "75   20904                1700    ELECTRIC  TOWNHOUSE    PRIMARY   \n",
       "76   20904                1700    ELECTRIC  TOWNHOUSE    PRIMARY   \n",
       "77   20904                1700    ELECTRIC  TOWNHOUSE    PRIMARY   \n",
       "\n",
       "             Date Bill Amount Days in Billing Cycle KWH Usage  \n",
       "73      2022 June         140                    30       800  \n",
       "74       2022 May         150                    31       900  \n",
       "75     2022 April         160                    31      1200  \n",
       "76     2022 March         265                    31      2000  \n",
       "77  2022 February         260                    30      2000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_electricity_usage.reset_index(inplace = True, drop =True)\n",
    "df_electricity_usage.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b5afce",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "- Depending on the approach you used and your dataset it may be a good idea to check for duplicated values. If there are duplicated values check the source and if they are true duplicates.\n",
    "- In the case above the repeated rows seem to be from the template. I can remove the template from the input_data folder and rerun the notebook which will fix the issue.\n",
    "- Reset index is an invaluable tool especially when creating dataframes or copying a subset of a dataframe. There may be reasons to keep the original dataframe index (i.e., when you want to reference back. \n",
    "\n",
    "Once the data is combined we can use various of the functions we have learned to explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a0a7f725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home Square Footage\n",
       "2400    27\n",
       "3200    13\n",
       "NA      13\n",
       "1700    13\n",
       "1006    12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_electricity_usage['Home Square Footage'].value_counts()\n",
    "# Here we can see a few issues such as the SQFEET."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e3e3d",
   "metadata": {},
   "source": [
    "Once the data is combined and cleaned into one dataframe we may want to export the combined dataframe as a CSV file, explore the data and evaluate if it needs further cleaning before using for analysis or model development. For example, the last rows in the df_electricity_usage were from the template and can be dropped and not needed. We also need to explore any issues that the dataset may have such as null values, duplicates, other data issues, and creating derived features as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc6f6a",
   "metadata": {},
   "source": [
    "# Reading Data Line By Line\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Many of the approaches below focus on reading data line by line. Loading and processing data line by line may be beneficial in some cases. This may be the case when a file may be too big to load locally in a computer or reading realtime data. In some cases, this approach may be more efficient (i.e., memory or processing perspective), make identifying error location easier, and allow reading a file in real-time. Note that in cases of large files other (better) options may include cloud environments where we may have more computational power at our disposal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59ab3e2",
   "metadata": {},
   "source": [
    "# Working with PDFs\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "There are various libraries that can read PDF's. Most common are PDFMiner and PyPDF2, however, none of the two are included in the Anaconda Python Distribution (potentially not as mature as other data science libraries). I have had the best experience converting the PDFs to HTML using Acrobat Pro (which requires a license) and then using an HTML Python library (like Beautifulsup) to extract the PDF text information which will include some information such as if the text is part of the heading, body, paragraph, etc. Other approaches may include converting to TXT and other type of files before processing. See the notebook '20_Working_with_WebData_and_API' for an example on working with PDF files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3906e76",
   "metadata": {},
   "source": [
    "# Python Built-In Functions for Loading Data (OPTIONAL)\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Python has various built-in functions to work with files. This sections discusses the open function which is used to Open a file and return the corresponding file object. The function has various parameters including the file directory and mode. The mode specifies the function (e.g., reading, writing). The following are the options for the mode:\n",
    "- 'r': open for reading (default)\n",
    "- 'w': open for writing, truncating the file first\n",
    "- 'x': open for exclusive creation, failing if the file already exists\n",
    "- 'a': open for writing, appending to the end of file if it exists\n",
    "- 'b' binary mode\n",
    "- 't' text mode (default)\n",
    "- '+' open for updating (reading and writing)\n",
    "\n",
    "Documentation References:\n",
    "- List of Python Built-in Functions https://docs.python.org/3/library/functions.html\n",
    "- Open Function: https://docs.python.org/3/library/functions.html#open"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0896ba9",
   "metadata": {},
   "source": [
    "## Open Function\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aff91af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t\tSpent Grain Bread\n",
      "\n",
      "\n",
      "\n",
      "\tI got this recipe from the 1985 Grain Brewing Issue of Zymurgy magazine.  I tried it as is, and wit bananas added and found it to make a good heavy bread.  The original article is by Clifford T. Newmn Jr. and he requests any original recipies to be sent to him at P.O. Box 193, Port Matilda, PA  1680\n",
      "\n",
      "\n",
      "\n",
      "\t-4 C. fresh spent grains (from your latest batch of \n",
      "\n",
      "\t-1 C. water               all grain beer)\n",
      "\n",
      "\t-1/2 C. oil\n",
      "\n",
      "\t-1/2 C. sugar\n",
      "\n",
      "\t-1/4 tsp. salt\n",
      "\n",
      "\t-1 Tbsp. dry baker's yeast\n",
      "\n",
      "\t-All-purpose flour (enough to make a stiff dough)\n",
      "\n",
      "\n",
      "\n",
      "\tPlace the spent grains and water into a blender or food processor and blend themn for 30 seconds. Ten put the blended grains in a large mixing bowl and add oil, sugar, salt and stir in the yeast. Addflour until you have a thick, workable dough. Put in a warm place to rise until doubled in size. The knead the dough and divide into three greased laof pans. Let the dough double in size again then bae in a preheated oven at 350 degrees for one hour and 15 minutes. Remove from oven and let cool on wre racks. Enjoy.\n",
      "\n",
      "\n",
      "\n",
      "\tFor storing grains until ready to make the bread, place them one half inch deep in a shallow bakingdish or cookie sheet and put them into the oven at 200 degrees. Stir the grains about every half hou until they feel dry. Then store in tightly sealed containers. If you see any drops of moisture in te containers it means the grains need to be dried longer.\n",
      "\n",
      "\n",
      "\n",
      "\tOnce dried, the grains will keep for a long time. They can be used dried or moist (fresh), and drie grains can be ground into flour. The recipe above is for moist (fresh) grains and if you are using ried grains, add on half cup of water for every four cups of grains in the recipe.\n",
      "\n",
      "\n",
      "\n",
      "\tI haven't tried the following recipe (yet) and am thinking of using wheat flour or flour from grain instead of white flour in my next batch of bread.\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tSpent Grains Granola\n",
      "\n",
      "\n",
      "\n",
      "\t-6 C. fresh spent grains\n",
      "\n",
      "\t-4 C. raw sunflour seeds\n",
      "\n",
      "\t-2 C. weat germ\n",
      "\n",
      "\t-1 C. bran\n",
      "\n",
      "\t-1 1/2 C. non-fat dry milk\n",
      "\n",
      "\t-2 tsp. salt\n",
      "\n",
      "\t-3 Tbsp. cinnamon\n",
      "\n",
      "\t-3/4 C. molasses\n",
      "\n",
      "\t-1/2 C. honey\n",
      "\n",
      "\t-3 Tbsp. vanilla extract\n",
      "\n",
      "\t-2 C. each--coconut, raisins, chopped cashews\n",
      "\n",
      "\n",
      "\n",
      "\tCombine first seven ingredients in a large bowl and mix well. Blend molasses, honey and vanilla in  small bowl, then add to the grains, mixing well. Spreat 1/2 inch deep on a large baking pan and bak at 250 degrees until light brown, stirring occasionally. Turn onto paper-covered surface. Mix last hree ingredients and combine with granola. Store in tightly sealed containers.0\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "X-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-X\n",
      "\n",
      "\n",
      "\n",
      " Another file downloaded from:                               NIRVANAnet(tm)\n",
      "\n",
      "\n",
      "\n",
      " & the Temple of the Screaming Electron   Jeff Hunter          510-935-5845\n",
      "\n",
      " Rat Head                                 Ratsnatcher          510-524-3649\n",
      "\n",
      " Burn This Flag                           Zardoz               408-363-9766\n",
      "\n",
      " realitycheck                             Poindexter Fortran   415-567-7043\n",
      "\n",
      " Lies Unlimited                           Mick Freen           415-583-4102\n",
      "\n",
      "\n",
      "\n",
      "   Specializing in conversations, obscure information, high explosives,\n",
      "\n",
      "       arcane knowledge, political extremism, diversive sexuality,\n",
      "\n",
      "       insane speculation, and wild rumours. ALL-TEXT BBS SYSTEMS.\n",
      "\n",
      "\n",
      "\n",
      "  Full access for first-time callers.  We don't want to know who you are,\n",
      "\n",
      "   where you live, or what your phone number is. We are not Big Brother.\n",
      "\n",
      "\n",
      "\n",
      "                          \"Raw Data for Raw Nerves\"\n",
      "\n",
      "\n",
      "\n",
      "X-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-X\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open(file = \"./input_data/bread.txt\", mode = 'r')\n",
    "for line in f:\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f23ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file at output_data/anotherfile.txt and delete the content.\n",
    "\n",
    "a = []\n",
    "for i in range(10):\n",
    "    a.append(\"All work and no play makes Jack a dull boy. \\nSecond Line. \\n\");\n",
    "f = open(\"./output_data/anotherfile.txt\", 'w')\n",
    "for line in a:\n",
    "    f.write(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8204a420",
   "metadata": {},
   "source": [
    "## With Statement\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "The \"with\" keyword sets up a Context Manager, which temporarily deals with how the code runs. In this case, it closes the file automatically when the clause is left. \n",
    "\n",
    "Documentation References:\n",
    "- With Statement: https://docs.python.org/3/reference/compound_stmts.html#the-with-statement\n",
    "- Compound statements: https://docs.python.org/3/reference/compound_stmts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before but using the breadd.txt file and list comprehensions and printing only up to line 4.\n",
    "lines = []\n",
    "\n",
    "with open('./input_data/bread.txt') as f:\n",
    "    lines = [line for line in f]\n",
    "print(lines[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lines) # Still returns a list object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove the new line characters (\\n) can use a .rstrip() function within the for loop.\n",
    "# To remove the tab character (\\t) can use a .lstrip() function for loop.\n",
    "# To remove both can use the strip in the for loop.\n",
    "lines = []\n",
    "\n",
    "with open('./input_data/bread.txt') as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "\n",
    "print(lines[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d5032",
   "metadata": {},
   "source": [
    "#### Example with Numerical Data in a TXT File\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./input_data/ex1data1.txt\") as f:\n",
    "    for line in f:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42083848",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(line) # Note that the line variable is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e70949",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [] # Initializing an empty list.\n",
    "\n",
    "with open(\"./input_data/ex1data1.txt\") as f:\n",
    "    for line in f:\n",
    "        lines.append(line)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c7ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lines) # Notes that in this case the lines are a list and can be accessed by element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf58d9",
   "metadata": {},
   "source": [
    "In this case where each line is two columns of data we may need to use a different approach. \n",
    "\n",
    "We can use the split function to separate the nubmers by the comma and may also need to change the string to a number (i.e., float in this case). Could later use Pandas and transform the data to a dataframe.\n",
    "\n",
    "Continue to the OS Library below to see how to process the data in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./input_data/ex1data1.txt\")\n",
    "data = []\n",
    "\n",
    "for line in f:\n",
    "    parsed_line = str.split(line,\",\") # Line or row of data in this example.\n",
    "    data_line = []\n",
    "    for element in parsed_line:\n",
    "        data_line.append(float(element))\n",
    "    data.append(data_line)\n",
    "print(data)\n",
    "f.close()\n",
    "\n",
    "# This produces a list within list where the inner list is the two columsn of data and the outer is the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830d896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) # Think number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3eb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[0]) # Think number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0]) # Row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f22d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data[0][0])) # Element within row of data.\n",
    "print(data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91d9ea",
   "metadata": {},
   "source": [
    "# JSON Library: JSON Files (OPTIONAL) \n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "In previous lectures we have explored how to export dictionary (i.e., JSON) to a Pandas Dataframes and viceversa. This section provide furhter examples on how to work with JSON data using the JSON library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing JSON to a FILE\n",
    "data = {}  \n",
    "data['people'] = []  \n",
    "data['people'].append({  \n",
    "    'name': 'Scott',\n",
    "    'website': 'umbc.edu',\n",
    "    'from': 'Maryland'\n",
    "})\n",
    "data['people'].append({  \n",
    "    'name': 'Larry',\n",
    "    'website': 'google.com',\n",
    "    'from': 'Michigan'\n",
    "})\n",
    "data['people'].append({  \n",
    "    'name': 'Tim',\n",
    "    'website': 'apple.com',\n",
    "    'from': 'Alabama'\n",
    "})\n",
    "#!mkdir outputs\n",
    "with open('./output_data/json_data.txt', 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005efeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading JSON from a TXT File\n",
    "with open('./output_data/json_data.txt') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for p in data['people']:\n",
    "        print('Name: ' + p['name'])\n",
    "        print('Website: ' + p['website'])\n",
    "        print('From: ' + p['from'])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b69473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Read\n",
    "f = open('./input_data/geo_data.json')\n",
    "data = json.load(f)\n",
    "f.close()    \n",
    "print(data)\n",
    "print('____________________________________')\n",
    "print(data[\"features\"])\n",
    "print('____________________________________')\n",
    "print(data[\"features\"][0][\"geometry\"])\n",
    "print('____________________________________')\n",
    "for i in data[\"features\"]:\n",
    "    print(i[\"geometry\"][\"coordinates\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2be82b6",
   "metadata": {},
   "source": [
    "# Working with CSV Files (CSV Library)\n",
    "[Return to Table of Contents](#Table-of-Contents)\n",
    "\n",
    "Note that previously we have learned to work with CSV data using the Pandas library and the Pandas library is the prefered approach. However, the CSV library exists and can be usefule too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./input_data/csv_plain_file.csv', newline='') \n",
    "reader = csv.reader(f, quoting = csv.QUOTE_NONNUMERIC)\n",
    "for row in reader: # A list of rows\n",
    "    for value in row: # A list of value\n",
    "        print(value) # Floats\n",
    "f.close() # Don't close until you are done with the reader;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e605130",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./input_data/addresses.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    firstnames, lastnames, streets, citys, states,zipcodes = [], [], [],[], [], []\n",
    "        \n",
    "    for row in readCSV:\n",
    "        firstname, lastname, street = row[0], row[1], row[2] \n",
    "        city, state, zipcode  = row[3], row[4], row[5]  \n",
    "\n",
    "        firstnames.append(firstname)\n",
    "        lastnames.append(lastname)\n",
    "        zipcodes.append(zipcode)\n",
    "\n",
    "    print(firstnames)\n",
    "    print(lastnames)\n",
    "    print(zipcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a41ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a new csv file from an existing one\n",
    "# New file will contain only the information that we want/need\n",
    "f2 = open('./output_data/dataout1.csv', 'w', newline='') \n",
    "writer = csv.writer(f2, delimiter=',')\n",
    "\n",
    "with open('./input_data/addresses.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    firstnames, lastnames, streets, citys, states,zipcodes = [], [], [],[], [], []\n",
    "        \n",
    "    for row in readCSV:\n",
    "        firstname, lastname, street = row[0], row[1], row[2] \n",
    "        city, state, zipcode  = row[3], row[4], row[5]\n",
    "        data2write = (firstname,lastname,state)\n",
    "        print(data2write)\n",
    "        writer.writerow(data2write)\n",
    "        \n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe4916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read csv and write txt\n",
    "\n",
    "with open('./input_data/addresses.csv') as csvfile:\n",
    "    f2 = open(\"./output_data/textout.txt\", \"w\")\n",
    "\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    firstnames, lastnames, streets, citys, states,zipcodes = [], [], [],[], [], []\n",
    "        \n",
    "    for row in readCSV:\n",
    "        firstname, lastname, street = row[0], row[1], row[2] \n",
    "        city, state, zipcode  = row[3], row[4], row[5]\n",
    "        text2write = firstname+' lives in '+ city +', '+state\n",
    "        print(text2write)\n",
    "        f2.write(text2write+'\\n')\n",
    "        \n",
    "    f2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5c4391",
   "metadata": {},
   "source": [
    "# Reading Multiple TXT Files (OPTIONAL)\n",
    "[Return to Table of Contents](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb55838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Fileinput library\n",
    "a = [\"./input_data/text_files/example3.txt\", \n",
    "     \"./input_data/text_files/Genescan.txt\", \n",
    "     \"./input_data/text_files/FAME.txt\"]\n",
    "b = fileinput.input(a)\n",
    "for line in b:\n",
    "    print(b.filename())\n",
    "    print(line)\n",
    "b.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe0a93",
   "metadata": {},
   "source": [
    "# NOTEBOOK END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f46bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590dff9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c51ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
