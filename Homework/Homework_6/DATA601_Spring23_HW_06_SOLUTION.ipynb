{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c96aff43",
   "metadata": {},
   "source": [
    "# STUDENT NAME AND INFORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a324c91",
   "metadata": {},
   "source": [
    "Note: For the cell above, feel free to use the markdown code from the class Jupyter Notebook and modify it with your information. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f1d48",
   "metadata": {},
   "source": [
    "## DATA 601 - Spring 2023\n",
    "### Homework Assignment 6\n",
    "\n",
    "#### Due-date: Monday 5/8/2023 midnight.\n",
    "The excercises in this homework provide instruction on what to do. Feel free to add as many code or markdown cells as you need. The main objective of this homework is to train a classification algorithm and predict a target. In this case we will be using the wine dataset from SKLearn and use various features of wine to predict a target. In this case the target will be defined as the \"class\". However, note that these algorithms can predict number as well as categorical values. The classification models steps (e.g., train, test, calculate metrics, etc)) discussed in class are the same here.\n",
    "\n",
    "Wine Dataset:\n",
    "- https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-recognition-dataset\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "SciKit Learn Datasets:\n",
    "- https://scikit-learn.org/stable/datasets\n",
    "\n",
    "Seaborn Datasets:\n",
    "- https://seaborn.pydata.org/generated/seaborn.load_dataset.html\n",
    "- https://github.com/mwaskom/seaborn-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4339b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bdd5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  wine_class  \n",
       "0                            3.92   1065.0           0  \n",
       "1                            3.40   1050.0           0  \n",
       "2                            3.17   1185.0           0  \n",
       "3                            3.45   1480.0           0  \n",
       "4                            2.93    735.0           0  \n",
       "..                            ...      ...         ...  \n",
       "173                          1.74    740.0           2  \n",
       "174                          1.56    750.0           2  \n",
       "175                          1.56    835.0           2  \n",
       "176                          1.62    840.0           2  \n",
       "177                          1.60    560.0           2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, target = load_wine(return_X_y=True, as_frame=True) # Loads the data and target\n",
    "df['wine_class'] = target.tolist() # Adds the target data as a new column in dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bed3f0",
   "metadata": {},
   "source": [
    "# Additional Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db5f84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn\n",
    "# Confusion matrix, Accuracy, sensitivity and specificity\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classification Models\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbfaa0c",
   "metadata": {},
   "source": [
    "# Question 1 (5 Points)\n",
    "Create a new df_filtered dataframe and only include class 0 and 1 in our dataset. We will use this in our classification models below and only predict class 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b889cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>12.07</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.17</td>\n",
       "      <td>21.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.28</td>\n",
       "      <td>378.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>12.43</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.29</td>\n",
       "      <td>21.5</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.69</td>\n",
       "      <td>2.84</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>127</td>\n",
       "      <td>11.79</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.78</td>\n",
       "      <td>28.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.76</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>2.44</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>12.37</td>\n",
       "      <td>1.63</td>\n",
       "      <td>2.30</td>\n",
       "      <td>24.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>342.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>12.04</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.38</td>\n",
       "      <td>22.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.57</td>\n",
       "      <td>580.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0        0    14.23        1.71  2.43               15.6      127.0   \n",
       "1        1    13.20        1.78  2.14               11.2      100.0   \n",
       "2        2    13.16        2.36  2.67               18.6      101.0   \n",
       "3        3    14.37        1.95  2.50               16.8      113.0   \n",
       "4        4    13.24        2.59  2.87               21.0      118.0   \n",
       "..     ...      ...         ...   ...                ...        ...   \n",
       "125    125    12.07        2.16  2.17               21.0       85.0   \n",
       "126    126    12.43        1.53  2.29               21.5       86.0   \n",
       "127    127    11.79        2.13  2.78               28.5       92.0   \n",
       "128    128    12.37        1.63  2.30               24.5       88.0   \n",
       "129    129    12.04        4.30  2.38               22.0       80.0   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "125           2.60        2.65                  0.37             1.35   \n",
       "126           2.74        3.15                  0.39             1.77   \n",
       "127           2.13        2.24                  0.58             1.76   \n",
       "128           2.22        2.45                  0.40             1.90   \n",
       "129           2.10        1.75                  0.42             1.35   \n",
       "\n",
       "     color_intensity   hue  od280/od315_of_diluted_wines  proline wine_class  \n",
       "0               5.64  1.04                          3.92   1065.0          0  \n",
       "1               4.38  1.05                          3.40   1050.0          0  \n",
       "2               5.68  1.03                          3.17   1185.0          0  \n",
       "3               7.80  0.86                          3.45   1480.0          0  \n",
       "4               4.32  1.04                          2.93    735.0          0  \n",
       "..               ...   ...                           ...      ...        ...  \n",
       "125             2.76  0.86                          3.28    378.0          1  \n",
       "126             3.94  0.69                          2.84    352.0          1  \n",
       "127             3.00  0.97                          2.44    466.0          1  \n",
       "128             2.12  0.89                          2.78    342.0          1  \n",
       "129             2.60  0.79                          2.57    580.0          1  \n",
       "\n",
       "[130 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df[df['wine_class'] < 2].reset_index()\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f81ca",
   "metadata": {},
   "source": [
    "# Question 2 (5 Points)\n",
    "Split the data into training (80%) and testing (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3c801f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features to use for prediction (X) and target (y)\n",
    "x = df_filtered.loc[:,['alcohol','malic_acid','ash','alcalinity_of_ash','magnesium','total_phenols',\n",
    "              'flavanoids','nonflavanoid_phenols','proanthocyanins','color_intensity','hue',\n",
    "              'od280/od315_of_diluted_wines','proline']].values\n",
    "y = df_filtered.loc[:,'wine_class'].values\n",
    "# Train/Test Split of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962c49b",
   "metadata": {},
   "source": [
    "# Question 3 (10 Points)\n",
    "Use SVM algorithm to predict the class and calculate metrics: Confustion Matrix, Accuracy, Sensitivity and Specificity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbcd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[12  1]\n",
      " [ 0 13]]\n",
      "Accuracy :  0.9615384615384616\n",
      "Sensitivity :  0.9230769230769231\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "total1=sum(sum(cm1))\n",
    "#neigh.score(X_test, y_test) # Accuracy from the .score function.\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0] + cm1[1,1]) / total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0] / (cm1[0,0] + cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "\n",
    "specificity1 = cm1[1,1] / (cm1[1,0] + cm1[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bae1dc",
   "metadata": {},
   "source": [
    "# Question 4 (10 Points)\n",
    "Use a random forest classifier to predict the class and calculate metrics: Confustion Matrix, Accuracy, Sensitivity and Specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de40a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[13  0]\n",
      " [ 0 13]]\n",
      "Accuracy :  1.0\n",
      "Sensitivity :  1.0\n",
      "Specificity :  1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "total1=sum(sum(cm1))\n",
    "#neigh.score(X_test, y_test) # Accuracy from the .score function.\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0] + cm1[1,1]) / total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0] / (cm1[0,0] + cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "\n",
    "specificity1 = cm1[1,1] / (cm1[1,0] + cm1[1,1])\n",
    "print('Specificity : ', specificity1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526cc8d1",
   "metadata": {},
   "source": [
    "# Question 5 (5 Points)\n",
    "How many datapoints do we have in this dataset? Provide thoughts and comments on the size of this dataset on at least two of the following:  \n",
    "- Which of the classification models above performed better?\n",
    "- What are some challenges of the size of this dataset?\n",
    "- Would you feel comfortable with using this dataset for predictions?\n",
    "- What could be some things that you could do for improving the outputs and performance of the models? This could include steps during the data cleaning/preparation/transformation, testing or training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ee6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wine dataset has 178 rows of data\n"
     ]
    }
   ],
   "source": [
    "print(f'The wine dataset has {df.shape[0]} rows of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a5cc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "Name: wine_class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['wine_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc6c96e",
   "metadata": {},
   "source": [
    "Full Answer:\n",
    "\n",
    "Of the two models SVM and Random Forests, Random Forests seems to have performed better.\n",
    "\n",
    "This dataset seems to be on the smaller side. It may make sense to evaluate with a subject matter expert or perform some other evaluations to make sure the size of this dataset is appropriate for a classification task. There may be a need to increase the amount of data and depending on how easy it is to obtain further data, it may make sense to do so.\n",
    "\n",
    "The data has three classes and only 178 records total. The value counts of the wine class 0 above shows that at best we have 71 wines with class 0. This means that during the train/test split of the data for this class only about 14 records would be part of the test data while the rest training. This is a really small number of records to perform testing, and calculate metrics and may not be a statistically significant sample.\n",
    "\n",
    "If we would have performed cleaning/preparation/transformation of the data one task that could have improved the outputs and the performance, these include:\n",
    "- evaluate need for data cleaning (e.g., removing outliers, missing values, etc.)\n",
    "- scaling of the data\n",
    "- feature selection\n",
    "\n",
    "Because the amount of data is so low we may not want to drop any rows of data. For scaling, there are few features (e.g., proline) that have relatively large values compared to the others. Feature selection may also improve the model predictive performance. Because the accuracy is so high and the amount of data so low, I don't expect that either scaling or feature selection will make any difference.\n",
    "\n",
    "We could also expand to do multi class or multi label classification instead of separating and do the binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77af58e",
   "metadata": {},
   "source": [
    "# Classification with SCALING AND MULTILABEL\n",
    "\n",
    "In this section we are exploring how to use scaling and multilabel classification including the multilabel classification matrix. SKLearn scaling functions and methods include MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "SKLearn Scalers:\n",
    "- https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "\n",
    "Multilabel Classification Confusion Matrix\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b45ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # Other SKLearn scalers StandardScaler, MaxAbsScaler, RobustScaler\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebddd4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.573840</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.970696</td>\n",
       "      <td>0.561341</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571053</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.274448</td>\n",
       "      <td>0.264505</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.550642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.646933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.558360</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.798535</td>\n",
       "      <td>0.857347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581579</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.259386</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>0.325963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.970356</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.205047</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.172161</td>\n",
       "      <td>0.329529</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.626482</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.336662</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.481283</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>0.073840</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.761092</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.397290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.331230</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.400856</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.664032</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.368966</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.201141</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alcohol  malic_acid       ash  alcalinity_of_ash  magnesium  \\\n",
       "0    0.842105    0.191700  0.572193           0.257732   0.619565   \n",
       "1    0.571053    0.205534  0.417112           0.030928   0.326087   \n",
       "2    0.560526    0.320158  0.700535           0.412371   0.336957   \n",
       "3    0.878947    0.239130  0.609626           0.319588   0.467391   \n",
       "4    0.581579    0.365613  0.807487           0.536082   0.521739   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "173  0.705263    0.970356  0.582888           0.510309   0.271739   \n",
       "174  0.623684    0.626482  0.598930           0.639175   0.347826   \n",
       "175  0.589474    0.699605  0.481283           0.484536   0.543478   \n",
       "176  0.563158    0.365613  0.540107           0.484536   0.543478   \n",
       "177  0.815789    0.664032  0.737968           0.716495   0.282609   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0         0.627586    0.573840              0.283019         0.593060   \n",
       "1         0.575862    0.510549              0.245283         0.274448   \n",
       "2         0.627586    0.611814              0.320755         0.757098   \n",
       "3         0.989655    0.664557              0.207547         0.558360   \n",
       "4         0.627586    0.495781              0.490566         0.444795   \n",
       "..             ...         ...                   ...              ...   \n",
       "173       0.241379    0.056962              0.735849         0.205047   \n",
       "174       0.282759    0.086498              0.566038         0.315457   \n",
       "175       0.210345    0.073840              0.566038         0.296530   \n",
       "176       0.231034    0.071730              0.754717         0.331230   \n",
       "177       0.368966    0.088608              0.811321         0.296530   \n",
       "\n",
       "     color_intensity       hue  od280/od315_of_diluted_wines   proline  \\\n",
       "0           0.372014  0.455285                      0.970696  0.561341   \n",
       "1           0.264505  0.463415                      0.780220  0.550642   \n",
       "2           0.375427  0.447154                      0.695971  0.646933   \n",
       "3           0.556314  0.308943                      0.798535  0.857347   \n",
       "4           0.259386  0.455285                      0.608059  0.325963   \n",
       "..               ...       ...                           ...       ...   \n",
       "173         0.547782  0.130081                      0.172161  0.329529   \n",
       "174         0.513652  0.178862                      0.106227  0.336662   \n",
       "175         0.761092  0.089431                      0.106227  0.397290   \n",
       "176         0.684300  0.097561                      0.128205  0.400856   \n",
       "177         0.675768  0.105691                      0.120879  0.201141   \n",
       "\n",
       "    wine_class  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "173          2  \n",
       "174          2  \n",
       "175          2  \n",
       "176          2  \n",
       "177          2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining features to use for prediction (X) and target (y)\n",
    "scaler = MinMaxScaler() #Creating StandardScaler Object\n",
    "# Note that scaling can also be performed during fitting step.\n",
    "df_scaled = df.copy() # Creating a copy of the dataframe\n",
    "df_scaled.iloc[:,:-1] = scaler.fit_transform(df_scaled.iloc[:,:-1]) # Scaling everything except target column\n",
    "\n",
    "# The Target needs to be an Object or will give an error in the multilabel confusion matrix.\n",
    "df_scaled['wine_class'] = df_scaled['wine_class'].astype(str)\n",
    "df_scaled # Scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6728b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features to use for prediction (X) and target (y)\n",
    "# Note we are using the full dataset and in this case using the index for feature selection and not using the values.\n",
    "x = df_scaled.iloc[:,:-1]\n",
    "y = df_scaled.iloc[:,13]\n",
    "# Split of the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367ee13",
   "metadata": {},
   "source": [
    "Note that if we are reussing a code block like in this case we are reussing the models and accuracy metrics. It makes sense to define a custom function rather than retyping like I am doing in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eab9696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[14  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1  8]]\n",
      "Accuracy :  0.75\n",
      "Sensitivity :  1.0\n",
      "Specificity :  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[22,  0],\n",
       "        [ 0, 14]],\n",
       "\n",
       "       [[22,  1],\n",
       "        [ 0, 13]],\n",
       "\n",
       "       [[27,  0],\n",
       "        [ 1,  8]]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "total1=sum(sum(cm1))\n",
    "#neigh.score(X_test, y_test) # Accuracy from the .score function.\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0] + cm1[1,1]) / total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0] / (cm1[0,0] + cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "\n",
    "specificity1 = cm1[1,1] / (cm1[1,0] + cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "# MultiLabel Confusion Matrix:\n",
    "multilabel_confusion_matrix(y_test, y_predict)\n",
    "# Note that either of the classification matrix are correct. It is different ways to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81f6c5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[14  0  0]\n",
      " [ 1 12  0]\n",
      " [ 0  0  9]]\n",
      "Accuracy :  0.7222222222222222\n",
      "Sensitivity :  1.0\n",
      "Specificity :  0.9230769230769231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[21,  1],\n",
       "        [ 0, 14]],\n",
       "\n",
       "       [[23,  0],\n",
       "        [ 1, 12]],\n",
       "\n",
       "       [[27,  0],\n",
       "        [ 0,  9]]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_predict)\n",
    "print('Confusion Matrix : \\n', cm1)\n",
    "total1=sum(sum(cm1))\n",
    "#neigh.score(X_test, y_test) # Accuracy from the .score function.\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy1 = (cm1[0,0] + cm1[1,1]) / total1\n",
    "print ('Accuracy : ', accuracy1)\n",
    "\n",
    "sensitivity1 = cm1[0,0] / (cm1[0,0] + cm1[0,1])\n",
    "print('Sensitivity : ', sensitivity1)\n",
    "\n",
    "specificity1 = cm1[1,1] / (cm1[1,0] + cm1[1,1])\n",
    "print('Specificity : ', specificity1)\n",
    "\n",
    "# MultiLabel Confusion Matrix:\n",
    "multilabel_confusion_matrix(y_test, y_predict)\n",
    "# Note that either of the classification matrix are correct. It is different ways to visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec15980a",
   "metadata": {},
   "source": [
    "# BONUS (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302eaee",
   "metadata": {},
   "source": [
    "We have the dataset below related to diamonds. \n",
    "1. Which feature could we predict?\n",
    "2. Which model would be an appropriate model to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a062d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset(\"diamonds\")\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2478c522",
   "metadata": {},
   "source": [
    "We could predict the price of the diamonds given the other features. We would need to use a model that can be used to predict continuous numeric values. The simplest model that we could use is a multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3f510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ede41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564db39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c4f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6c128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
